{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blank_swift.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacopoMangiavacchi/Swift-TensorFlow-Sample-Notebooks/blob/master/FizzBuzz_Swift_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kZRlD4utdPuX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import Foundation\n",
        "import TensorFlow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V1iJ2NkG19Si",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "func bitEncode(_ n: UInt, bits: Int = 10) -> [Float] {\n",
        "    var array = [Float](repeating: 0, count: bits)\n",
        "    for i in 0..<bits {\n",
        "        array[bits - 1 - i] = Float(n >> i & 1)\n",
        "    }\n",
        "    return array\n",
        "}\n",
        "\n",
        "func labelEncode(_ n: UInt) -> [Float] {\n",
        "    guard n > 0 else { return [0, 0, 0, 1] }\n",
        "    var array: [Float] = [0, 0, 0, 0]\n",
        "\n",
        "    if n % 15 == 0 {\n",
        "        array[0] = 1\n",
        "    }\n",
        "    else if n % 3 == 0 {\n",
        "        array[1] = 1\n",
        "    }\n",
        "    else if n % 5 == 0 {\n",
        "        array[2] = 1\n",
        "    }\n",
        "    else {\n",
        "        array[3] = 1\n",
        "    }\n",
        "\n",
        "    return array\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2qwdXkr2viX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "let start = 101\n",
        "let end = 1024\n",
        "var X = [[Float]]()\n",
        "var Y = [[Float]]()\n",
        "\n",
        "for i in start..<end {\n",
        "    X.append(bitEncode(UInt(i)))\n",
        "    Y.append(labelEncode(UInt(i)))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_e1hzXeb8J5d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "struct FizzBuzz: Layer {\n",
        "    var l1: Dense<Float>\n",
        "    var l2: Dense<Float>\n",
        "\n",
        "    init(variables: Int = 1) {\n",
        "        l1 = Dense<Float>(inputSize: variables, outputSize: 50, activation: tanh)\n",
        "        l2 = Dense<Float>(inputSize: 50, outputSize: 4, activation: softmax) // {$0}\n",
        "    }\n",
        "    \n",
        "    @differentiable(wrt: (self, input))\n",
        "    func applied(to input: Tensor<Float>) -> Tensor<Float> {\n",
        "        let output = l1.applied(to: input)\n",
        "        return l2.applied(to: output)\n",
        "\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JdGxV6K2VZ2X",
        "colab_type": "code",
        "outputId": "b4cf864f-65b3-40b7-b26d-729ce7aff908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "let x = Tensor<Float>(shape: [Int32(end - start), 10], scalars: Array(X.joined()))\n",
        "let y = Tensor<Float>(shape: [Int32(end - start), 4], scalars: Array(Y.joined()))\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorShape(dimensions: [923, 10])\r\n",
            "TensorShape(dimensions: [923, 4])\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OkEgM40GQGKG",
        "colab_type": "code",
        "outputId": "597a55bd-2f8f-450b-fd9d-ad3c1a82752d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "cell_type": "code",
      "source": [
        "let optimizer = RMSProp<FizzBuzz, Float>(learningRate: 0.03)\n",
        "var model = FizzBuzz(variables: 10)\n",
        "\n",
        "\n",
        "for epoch in 1...10000 {\n",
        "    let (cost, ùõÅmodel) = model.valueWithGradient { m -> Tensor<Float> in\n",
        "        let ≈∑ = m.applied(to: x)\n",
        "        //return meanSquaredError(predicted: ≈∑, expected: y)\n",
        "        return softmaxCrossEntropy(logits: ≈∑, labels: y)\n",
        "    }\n",
        "    optimizer.update(&model.allDifferentiableVariables, along: ùõÅmodel)\n",
        "  \n",
        "    if epoch % 1000 == 0 {\n",
        "        print(\"Epoch: \\(epoch) Cost: \\(cost)\")\n",
        "    }\n",
        "}"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1000 Cost: 1.1768423\n",
            "Epoch: 2000 Cost: 1.1716907\n",
            "Epoch: 3000 Cost: 1.1489633\n",
            "Epoch: 4000 Cost: 1.0425111\n",
            "Epoch: 5000 Cost: 0.8467724\n",
            "Epoch: 6000 Cost: 0.803761\n",
            "Epoch: 7000 Cost: 0.8016894\n",
            "Epoch: 8000 Cost: 0.7999455\n",
            "Epoch: 9000 Cost: 0.7961145\n",
            "Epoch: 10000 Cost: 0.79708433\n",
            "Epoch: 11000 Cost: 0.7959698\n",
            "Epoch: 12000 Cost: 0.7967748\n",
            "Epoch: 13000 Cost: 0.7967497\n",
            "Epoch: 14000 Cost: 0.79602313\n",
            "Epoch: 15000 Cost: 0.79610425\n",
            "Epoch: 16000 Cost: 0.796049\n",
            "Epoch: 17000 Cost: 0.7959788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "",
          "evalue": "ignored",
          "traceback": [
            "Current stack trace:",
            "\tframe #16: 0x00007fa238758621 $__lldb_expr46`partial apply for AD__$s14__lldb_expr_458FizzBuzzV7applied2to10TensorFlow0G0VySfGAI_tF__adjoint_src_0_wrt_0_1 [inlined] AD__$s14__lldb_expr_458FizzBuzzV7applied2to10TensorFlow0G0VySfGAI_tF__adjoint_src_0_wrt_0_1 at <Cell 4>:12:25",
            "\tframe #18: 0x00007fa2386f35fa $__lldb_expr245`partial apply for AD__$s15__lldb_expr_24410TensorFlow0C0VySfG02__a1_B3_458FizzBuzzVXEfU___adjoint_src_0_wrt_0 [inlined] AD__$s15__lldb_expr_24410TensorFlow0C0VySfG02__a1_B3_458FizzBuzzVXEfU___adjoint_src_0_wrt_0 at <Cell 16>:7:20",
            "\tframe #26: 0x00007fa2386f24ae $__lldb_expr245`main at <Cell 16>:6"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8u2dYDdbC0OP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "var X_test = [[Float]]()\n",
        "var Y_true = [[Float]]()\n",
        "\n",
        "for i in 0..<100 {\n",
        "    X_test.append(bitEncode(UInt(i)))\n",
        "    Y_true.append(labelEncode(UInt(i)))\n",
        "}\n",
        "\n",
        "let xTest = Tensor<Float>(shape: [100, 10], scalars: Array(X_test.joined()))\n",
        "let yTest = model.applied(to: xTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JxsXeC37EqEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "ebd83697-a2a2-4443-f1c1-e49c30f5c30b"
      },
      "cell_type": "code",
      "source": [
        "let yMax = yTest.argmax(squeezingAxis: 1).array\n",
        "let yArray = Array(yTest.array)\n",
        "let description = [\"FizzBuzz\", \"Fizz    \", \"Buzz    \", \"        \"]\n",
        "\n",
        "for i in 0..<100 {\n",
        "    print(i, description[Int(yMax[i].description)!], Y_true[i], yArray[i])\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0          [0.0, 0.0, 0.0, 1.0] [0.03104766, 0.22917551, 0.03687466, 0.70290214]\r\n",
            "1          [0.0, 0.0, 0.0, 1.0] [0.013110635, 0.22353785, 0.017794633, 0.74555683]\r\n",
            "2          [0.0, 0.0, 0.0, 1.0] [0.010598051, 0.20600991, 0.010907119, 0.7724849]\r\n",
            "3          [0.0, 1.0, 0.0, 0.0] [0.005083005, 0.19560903, 0.00587185, 0.7934361]\r\n",
            "4          [0.0, 0.0, 0.0, 1.0] [0.015403566, 0.14548033, 0.013219786, 0.8258963]\r\n",
            "5          [0.0, 0.0, 1.0, 0.0] [0.006811601, 0.14471091, 0.0068619354, 0.84161556]\r\n",
            "6          [0.0, 1.0, 0.0, 0.0] [0.005727165, 0.13162926, 0.004264116, 0.8583795]\r\n",
            "7          [0.0, 0.0, 0.0, 1.0] [0.0029154378, 0.1304868, 0.002589199, 0.86400855]\r\n",
            "8          [0.0, 0.0, 0.0, 1.0] [0.013146905, 0.18292326, 0.021933408, 0.7819964]\r\n",
            "9          [0.0, 1.0, 0.0, 0.0] [0.005595836, 0.17396554, 0.010341, 0.81009763]\r\n",
            "10          [0.0, 0.0, 1.0, 0.0] [0.0048841033, 0.16894081, 0.0070882635, 0.8190868]\r\n",
            "11          [0.0, 0.0, 0.0, 1.0] [0.0023550966, 0.15796624, 0.0038289197, 0.83584976]\r\n",
            "12          [0.0, 1.0, 0.0, 0.0] [0.0070652305, 0.119979225, 0.00835402, 0.86460155]\r\n",
            "13          [0.0, 0.0, 0.0, 1.0] [0.0031184275, 0.11655422, 0.0042033195, 0.876124]\r\n",
            "14          [0.0, 0.0, 0.0, 1.0] [0.0029336053, 0.115692, 0.0030464493, 0.878328]\r\n",
            "15          [1.0, 0.0, 0.0, 0.0] [0.0014837639, 0.112512894, 0.0018339618, 0.88416946]\r\n",
            "16          [0.0, 0.0, 0.0, 1.0] [0.00911555, 0.16508594, 0.01609171, 0.80970675]\r\n",
            "17          [0.0, 0.0, 0.0, 1.0] [0.0044878577, 0.17097333, 0.008919018, 0.81561977]\r\n",
            "18          [0.0, 1.0, 0.0, 0.0] [0.0033130704, 0.14493676, 0.005159782, 0.8465904]\r\n",
            "19          [0.0, 0.0, 0.0, 1.0] [0.001889432, 0.14936914, 0.003334057, 0.84540737]\r\n",
            "20          [0.0, 0.0, 1.0, 0.0] [0.004780302, 0.10366983, 0.006397379, 0.8851525]\r\n",
            "21          [0.0, 1.0, 0.0, 0.0] [0.002579697, 0.10993274, 0.0038581318, 0.8836293]\r\n",
            "22          [0.0, 0.0, 0.0, 1.0] [0.0019782064, 0.09344375, 0.002322341, 0.9022557]\r\n",
            "23          [0.0, 0.0, 0.0, 1.0] [0.0012140824, 0.099393, 0.0016466089, 0.8977462]\r\n",
            "24          [0.0, 1.0, 0.0, 0.0] [0.0039820555, 0.12700924, 0.009578379, 0.8594303]\r\n",
            "25          [0.0, 0.0, 1.0, 0.0] [0.0019949635, 0.12825292, 0.005087055, 0.864665]\r\n",
            "26          [0.0, 0.0, 0.0, 1.0] [0.0016014171, 0.11565309, 0.0033995726, 0.87934595]\r\n",
            "27          [0.0, 1.0, 0.0, 0.0] [0.00092722714, 0.11644629, 0.00215162, 0.88047487]\r\n",
            "28          [0.0, 0.0, 0.0, 1.0] [0.0022878533, 0.083377875, 0.0040741838, 0.91026014]\r\n",
            "29          [0.0, 0.0, 0.0, 1.0] [0.0012277236, 0.085110284, 0.0023179222, 0.9113441]\r\n",
            "30          [1.0, 0.0, 0.0, 0.0] [0.0010664924, 0.080587424, 0.0016847018, 0.9166613]\r\n",
            "31          [0.0, 0.0, 0.0, 1.0] [0.0006517473, 0.08307345, 0.0011542784, 0.91512054]\r\n",
            "32          [0.0, 0.0, 0.0, 1.0] [0.0069870097, 0.122155584, 0.013182841, 0.8576746]\r\n",
            "33          [0.0, 1.0, 0.0, 0.0] [0.0029119889, 0.114245325, 0.006049289, 0.87679344]\r\n",
            "34          [0.0, 0.0, 0.0, 1.0] [0.0024794678, 0.110364266, 0.004112418, 0.8830438]\r\n",
            "35          [0.0, 0.0, 1.0, 0.0] [0.0011656733, 0.101606786, 0.0021522117, 0.89507526]\r\n",
            "36          [0.0, 1.0, 0.0, 0.0] [0.0035373827, 0.07620802, 0.004903438, 0.9153511]\r\n",
            "37          [0.0, 0.0, 0.0, 1.0] [0.0015819976, 0.073765226, 0.0024663096, 0.92218655]\r\n",
            "38          [0.0, 0.0, 0.0, 1.0] [0.0014131599, 0.070552334, 0.0016818026, 0.9263528]\r\n",
            "39          [0.0, 1.0, 0.0, 0.0] [0.0007104859, 0.06806561, 0.0009917542, 0.9302322]\r\n",
            "40          [0.0, 0.0, 1.0, 0.0] [0.0030252577, 0.0971071, 0.007539843, 0.8923277]\r\n",
            "41          [0.0, 0.0, 0.0, 1.0] [0.0012834383, 0.0888991, 0.0034275125, 0.90638995]\r\n",
            "42          [0.0, 1.0, 0.0, 0.0] [0.0011853941, 0.094233766, 0.002650187, 0.90193063]\r\n",
            "43          [0.0, 0.0, 0.0, 1.0] [0.0005676476, 0.08537921, 0.001400078, 0.9126531]\r\n",
            "44          [0.0, 0.0, 0.0, 1.0] [0.001725102, 0.06514911, 0.0031306797, 0.9299951]\r\n",
            "45          [1.0, 0.0, 0.0, 0.0] [0.00077719893, 0.061513834, 0.0015471872, 0.9361618]\r\n",
            "46          [0.0, 0.0, 0.0, 1.0] [0.00075772346, 0.064771876, 0.0012075485, 0.9332629]\r\n",
            "47          [0.0, 0.0, 0.0, 1.0] [0.00038529845, 0.061221674, 0.00071209297, 0.937681]\r\n",
            "48          [0.0, 1.0, 0.0, 0.0] [0.0021280719, 0.08432407, 0.0055987076, 0.9079492]\r\n",
            "49          [0.0, 0.0, 0.0, 1.0] [0.0010646039, 0.08743254, 0.0030317176, 0.9084712]\r\n",
            "50          [0.0, 0.0, 1.0, 0.0] [0.0007897821, 0.07534185, 0.0019303318, 0.921938]\r\n",
            "51          [0.0, 1.0, 0.0, 0.0] [0.0004445979, 0.07747085, 0.0012053086, 0.9208792]\r\n",
            "52          [0.0, 0.0, 0.0, 1.0] [0.0011861244, 0.054419782, 0.0024266334, 0.9419674]\r\n",
            "53          [0.0, 0.0, 0.0, 1.0] [0.00065034174, 0.057534233, 0.0014413602, 0.9403741]\r\n",
            "54          [0.0, 1.0, 0.0, 0.0] [0.00051089254, 0.04992677, 0.000941603, 0.9486208]\r\n",
            "55          [0.0, 0.0, 1.0, 0.0] [0.00030989965, 0.05281036, 0.00064591225, 0.94623375]\r\n",
            "56          [0.0, 0.0, 0.0, 1.0] [0.00096921995, 0.06519036, 0.003289374, 0.93055105]\r\n",
            "57          [0.0, 1.0, 0.0, 0.0] [0.0004936596, 0.065504394, 0.0017384175, 0.93226355]\r\n",
            "58          [0.0, 0.0, 0.0, 1.0] [0.00040428207, 0.062253818, 0.001274789, 0.93606716]\r\n",
            "59          [0.0, 0.0, 0.0, 1.0] [0.00023366885, 0.06253541, 0.0007929295, 0.936438]\r\n",
            "60          [1.0, 0.0, 0.0, 0.0] [0.00061098766, 0.04532335, 0.001591689, 0.952474]\r\n",
            "61          [0.0, 0.0, 0.0, 1.0] [0.00033575, 0.045820247, 0.0009115592, 0.9529324]\r\n",
            "62          [0.0, 0.0, 0.0, 1.0] [0.00029294664, 0.044650223, 0.00069289363, 0.95436394]\r\n",
            "63          [0.0, 1.0, 0.0, 0.0] [0.00018037895, 0.04571336, 0.00046888404, 0.9536375]\r\n",
            "64          [0.0, 0.0, 0.0, 1.0] [0.009719754, 0.14427719, 0.010556147, 0.83544683]\r\n",
            "65          [0.0, 0.0, 1.0, 0.0] [0.0042227986, 0.13617717, 0.005250664, 0.8543494]\r\n",
            "66          [0.0, 1.0, 0.0, 0.0] [0.0033742357, 0.12560171, 0.0032288167, 0.8677953]\r\n",
            "67          [0.0, 0.0, 0.0, 1.0] [0.0017506467, 0.12071558, 0.0018680304, 0.8756657]\r\n",
            "68          [0.0, 0.0, 0.0, 1.0] [0.005094125, 0.0912558, 0.004127154, 0.8995229]\r\n",
            "69          [0.0, 1.0, 0.0, 0.0] [0.0023002555, 0.08871172, 0.002244047, 0.906744]\r\n",
            "70          [0.0, 0.0, 1.0, 0.0] [0.0019926631, 0.082945526, 0.0014249046, 0.91363686]\r\n",
            "71          [0.0, 0.0, 0.0, 1.0] [0.0010705754, 0.08304532, 0.000922606, 0.9149615]\r\n",
            "72          [0.0, 1.0, 0.0, 0.0] [0.004215406, 0.1153955, 0.006394109, 0.87399495]\r\n",
            "73          [0.0, 0.0, 0.0, 1.0] [0.001846479, 0.10816522, 0.0031692854, 0.886819]\r\n",
            "74          [0.0, 0.0, 0.0, 1.0] [0.0016440768, 0.10781595, 0.0021857824, 0.8883542]\r\n",
            "75          [1.0, 0.0, 0.0, 0.0] [0.0008565587, 0.10334445, 0.0012921358, 0.89450693]\r\n",
            "76          [0.0, 0.0, 0.0, 1.0] [0.0024835102, 0.07901176, 0.0027267777, 0.9157779]\r\n",
            "77          [0.0, 0.0, 0.0, 1.0] [0.0011201046, 0.075826235, 0.0014614603, 0.92159224]\r\n",
            "78          [0.0, 1.0, 0.0, 0.0] [0.0010912356, 0.077377014, 0.0010566817, 0.920475]\r\n",
            "79          [0.0, 0.0, 0.0, 1.0] [0.0005847611, 0.07670507, 0.0006933866, 0.92201674]\r\n",
            "80          [0.0, 0.0, 1.0, 0.0] [0.0030178262, 0.102517106, 0.0049937945, 0.8894713]\r\n",
            "81          [0.0, 1.0, 0.0, 0.0] [0.0015467263, 0.105740346, 0.0028973005, 0.8898156]\r\n",
            "82          [0.0, 0.0, 0.0, 1.0] [0.0011796426, 0.09174941, 0.0017112363, 0.90535975]\r\n",
            "83          [0.0, 0.0, 0.0, 1.0] [0.0007092662, 0.09645275, 0.0011664579, 0.9016715]\r\n",
            "84          [0.0, 1.0, 0.0, 0.0] [0.0017616879, 0.064920396, 0.0022458446, 0.9310721]\r\n",
            "85          [0.0, 0.0, 1.0, 0.0] [0.0009601215, 0.06832926, 0.0014027565, 0.9293078]\r\n",
            "86          [0.0, 0.0, 0.0, 1.0] [0.0007936973, 0.060856912, 0.00087776646, 0.9374717]\r\n",
            "87          [0.0, 1.0, 0.0, 0.0] [0.0004954171, 0.065502346, 0.00064645644, 0.9333557]\r\n",
            "88          [0.0, 0.0, 0.0, 1.0] [0.0013820122, 0.08039958, 0.003104782, 0.9151136]\r\n",
            "89          [0.0, 0.0, 0.0, 1.0] [0.000718804, 0.08161831, 0.0017520101, 0.9159108]\r\n",
            "90          [1.0, 0.0, 0.0, 0.0] [0.000609867, 0.07700499, 0.0011914488, 0.92119366]\r\n",
            "91          [0.0, 0.0, 0.0, 1.0] [0.00037187195, 0.079959005, 0.0008154667, 0.91885364]\r\n",
            "92          [0.0, 0.0, 0.0, 1.0] [0.00090403215, 0.05521855, 0.0015163337, 0.94236106]\r\n",
            "93          [0.0, 1.0, 0.0, 0.0] [0.00049329596, 0.056441545, 0.0009097344, 0.9421554]\r\n",
            "94          [0.0, 0.0, 0.0, 1.0] [0.00045917154, 0.056028083, 0.0006684593, 0.9428443]\r\n",
            "95          [0.0, 0.0, 1.0, 0.0] [0.0002876831, 0.058938093, 0.00048889825, 0.9402853]\r\n",
            "96          [0.0, 1.0, 0.0, 0.0] [0.002385659, 0.07552145, 0.004060791, 0.91803205]\r\n",
            "97          [0.0, 0.0, 0.0, 1.0] [0.0010047272, 0.06898806, 0.0019346393, 0.92807263]\r\n",
            "98          [0.0, 0.0, 0.0, 1.0] [0.0009121183, 0.06913639, 0.0013423519, 0.92860913]\r\n",
            "99          [0.0, 1.0, 0.0, 0.0] [0.00044482292, 0.063827656, 0.0007452157, 0.9349823]\r\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}